{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daliaydom/Tarea2_AprendizajeProfundo/blob/main/Ejercicio3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5tmzk6NOacg"
      },
      "source": [
        "# Reconocimiento de acciones humanas usando RNNs \n",
        "\n",
        "Curso: [Aprendizaje Profundo](http://turing.iimas.unam.mx/~gibranfp/cursos/aprendizaje_profundo/). Profesor: [Gibran Fuentes Pineda](http://turing.iimas.unam.mx/~gibranfp/). Ayudantes: [Bere](https://turing.iimas.unam.mx/~bereml/) y [Ricardo](https://turing.iimas.unam.mx/~ricardoml/).\n",
        "\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "En esta libreta entrenaremos un modelo basado en RNNs para reconocimiento de acciones humanas (HAR) en el conjunto [UCF11](https://www.crcv.ucf.edu/data/UCF_YouTube_Action.php).\n",
        "\n",
        "<img src=\"https://www.crcv.ucf.edu/data/youtube_snaps.jpg\" width=800/>\n",
        "\n",
        "Este ejemplo está basado en las ideas presentadas en [*Long-term Recurrent Convolutional Networks for Visual Recognition and Description*](https://arxiv.org/abs/1411.4389) de 2016 por Donahue et al. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWJ1QYZ8Oacu"
      },
      "source": [
        "## 1 Preparación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rq2FNXPOacv"
      },
      "source": [
        "### 1.1 Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhYelX4LOacw",
        "outputId": "ca542419-db90-4c1c-9871-d366fafb5039"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.7.1-py3-none-any.whl (22 kB)\n"
          ]
        }
      ],
      "source": [
        "# Colab\n",
        "# https://github.com/TylerYep/torchinfo\n",
        "!pip install torchinfo\n",
        "# https://zarr.readthedocs.io/en/stable/\n",
        "!pip install zarr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ny0L2LzogTN-"
      },
      "outputs": [],
      "source": [
        "# sistema de archivos\n",
        "import os\n",
        "# funciones aleatorias\n",
        "import random\n",
        "# descomprimir\n",
        "import tarfile\n",
        "# sistema de archivos\n",
        "from os.path import join\n",
        "\n",
        "# arreglos multidimensionales\n",
        "import numpy as np\n",
        "# redes neuronales\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets.utils as tvu\n",
        "# almacenamiento de arreglos multidimensionales\n",
        "import zarr\n",
        "#redes\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "# inspección de arquitectura\n",
        "from torchinfo import summary\n",
        "\n",
        "# directorio de datos\n",
        "DATA_DIR = '../data'\n",
        "\n",
        "# tamaño del lote\n",
        "BATCH_SIZE = 32\n",
        "# tamaño del vector de características\n",
        "FEAT_SIZE = 1024\n",
        "\n",
        "# reproducibilidad\n",
        "SEED = 0\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch_gen = torch.manual_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijxWHO0POacz"
      },
      "source": [
        "## 2 Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJ2cr3FxOacz"
      },
      "source": [
        "### 2.1 Conjunto de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKOAC63YOacz"
      },
      "outputs": [],
      "source": [
        "class UCF11:\n",
        "\n",
        "    def __init__(self, root, download=False):\n",
        "        self.root = root\n",
        "        self.zarr_dir = join(root, 'ucf11.zarr')\n",
        "        if download:\n",
        "            self.download()\n",
        "        self.z = zarr.open(self.zarr_dir, 'r')\n",
        "        self.paths = list(self.z.array_keys())\n",
        "        \n",
        "    def __getitem__(self, i):\n",
        "        arr = self.z[self.paths[i]]\n",
        "        x = np.array(arr)\n",
        "        y = np.array(arr.attrs['y'], dtype=np.int64)\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "    \n",
        "    def _check_integrity(self):\n",
        "        return os.path.isdir(self.zarr_dir)\n",
        "    \n",
        "    def _extract(self, root, filename):\n",
        "        tar = tarfile.open(join(root, filename), \"r:gz\")\n",
        "        tar.extractall(root)\n",
        "        tar.close()\n",
        "\n",
        "    def download(self):\n",
        "        if self._check_integrity():\n",
        "            print('Files already downloaded and verified')\n",
        "            return\n",
        "        tvu.download_url(\n",
        "            url='https://cloud.xibalba.com.mx/s/apYrNA4iM4K65o7/download',\n",
        "            root=self.root,\n",
        "            filename='ucf11.zarr.tar.gz',\n",
        "            md5='c8a82454f9ec092d00bcd99c849e03fd'\n",
        "        )\n",
        "        self._extract(self.root, 'ucf11.zarr.tar.gz')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EH3mfqzOac0"
      },
      "source": [
        "### 2.2 Instancia del conjunto y partición"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvOlOFXhOac0"
      },
      "outputs": [],
      "source": [
        "ds = UCF11(join(DATA_DIR, 'ucf11'), True)\n",
        "x, y = ds[0]\n",
        "print(f'x shape={x.shape} dtype={x.dtype}')\n",
        "print(f'x [0][:5]={x[0][:5]}')\n",
        "print(f'y shape={y.shape} dtype={y.dtype} {y}')\n",
        "print(f'y {y}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkVb_fNSOac1"
      },
      "outputs": [],
      "source": [
        "trn_size = int(0.8 * len(ds))\n",
        "tst_size = len(ds) - trn_size\n",
        "trn_ds, tst_ds = random_split(ds, [trn_size, tst_size])\n",
        "len(trn_ds), len(tst_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgU1kjIKOac2"
      },
      "source": [
        "### 2.3 Cargadores de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nk3dtTvbOac2"
      },
      "outputs": [],
      "source": [
        "trn_dl = DataLoader(\n",
        "    # conjunto\n",
        "    trn_ds,\n",
        "    # tamaño del lote\n",
        "    batch_size=BATCH_SIZE,\n",
        "    # desordenar\n",
        "    shuffle=True,\n",
        "    # procesos paralelos\n",
        "    num_workers=2\n",
        ")\n",
        "tst_dl = DataLoader(\n",
        "    # conjunto\n",
        "    tst_ds,\n",
        "    # tamaño del lote\n",
        "    batch_size=BATCH_SIZE,\n",
        "    # desordenar\n",
        "    shuffle=True,\n",
        "    # procesos paralelos\n",
        "    num_workers=2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oFeu0qiOac4"
      },
      "outputs": [],
      "source": [
        "x, y = next(iter(trn_dl))\n",
        "print(f'x shape={x.shape} dtype={x.dtype}')\n",
        "print(f'y shape={y.shape} dtype={y.dtype}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0g9PTbMzOac4"
      },
      "source": [
        "## 3 Modelo\n",
        "\n",
        "<!-- Torchvision provee una familia de [modelos](https://pytorch.org/docs/1.6.0/torchvision/models.html#classification) preentrenados en ImageNet. Usaremos [Shufflenet V2](https://arxiv.org/abs/1807.11164), una arquitectura eficiente para clasificación de imágenes.  -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LQNTUmXOac4"
      },
      "source": [
        "### 3.1 Definiciones de arquitecturas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uUkIgMxPIEc"
      },
      "source": [
        "#### 3.1.1 CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUdVt_KdTnC-"
      },
      "source": [
        "The model is defined as a Sequential Keras model, for simplicity.\n",
        "\n",
        "We will define the model as having two 1D CNN layers, followed by a dropout layer for regularization, then a pooling layer. It is common to define CNN layers in groups of two in order to give the model a good chance of learning features from the input data. CNNs learn very quickly, so the dropout layer is intended to help slow down the learning process and hopefully result in a better final model. The pooling layer reduces the learned features to 1/4 their size, consolidating them to only the most essential elements.\n",
        "\n",
        "After the CNN and pooling, the learned features are flattened to one long vector and pass through a fully connected layer before the output layer used to make a prediction. The fully connected layer ideally provides a buffer between the learned features and the output with the intent of interpreting the learned features before making a prediction.\n",
        "\n",
        "For this model, we will use a standard configuration of 64 parallel feature maps and a kernel size of 3. The feature maps are the number of times the input is processed or interpreted, whereas the kernel size is the number of input time steps considered as the input sequence is read or processed onto the feature maps.\n",
        "\n",
        "The efficient Adam version of stochastic gradient descent will be used to optimize the network, and the categorical cross entropy loss function will be used given that we are learning a multi-class classification problem.\n",
        "\n",
        "The definition of the model is listed below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "29FYX-TEP7uv"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels=10, out_channels=4, num_classes=11):\n",
        "        super(CNN, self).__init__()\n",
        "        self.num_feats = 4*5*512\n",
        "        # O1,O2=out_channels=out_channels\n",
        "        self.cnn= nn.Sequential(\n",
        "            # bloque conv1\n",
        "            # [N, 1, 10, 1024] => [N, 4, 10, 1024]\n",
        "            nn.Conv1d(in_channels=in_channels,out_channels=out_channels,kernel_size=3,padding=1),\n",
        "            # nn.Conv1d(in_channels=O1,out_channels=O2,kernel_size=3,bias=True),\n",
        "            nn.Dropout(0.5),\n",
        "            # [N, 4, 10, 1024] => [N, 4, 5, 512]\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        # [N, 4, 5, 512] => [N, 4x5x512]\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # [N, 4x5x512] => [N, 1]\n",
        "        self.cls = nn.Linear(self.num_feats, num_classes)\n",
        "\n",
        "    # metodo para inferencia\n",
        "    def forward(self, x):\n",
        "        x = self.cnn(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.cls(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZOgH4sr6bKRD"
      },
      "outputs": [],
      "source": [
        "modelCNN = CNN()\n",
        "print(modelCNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6S3AaDQBcQT8"
      },
      "outputs": [],
      "source": [
        "summary(modelCNN, (1, 10, 1024), device='cpu', verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRrT9f02PXe6"
      },
      "source": [
        "#### 3.1.2 RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6Ai-d4WOac4"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size=1024, hidden_size=128, num_classes=11):\n",
        "        super().__init__()\n",
        "        self.bn = nn.BatchNorm1d(input_size)\n",
        "        self.rnn = nn.GRU(input_size=input_size, hidden_size=hidden_size,\n",
        "                          num_layers=1, batch_first=True)\n",
        "        self.cls = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Batch, Seq, Feats, Hidden\n",
        "        # [B, S, F] => [B, F, S]\n",
        "        x = x.movedim(1, 2)\n",
        "        # [B, F, S]\n",
        "        x = self.bn(x)\n",
        "        # [B, F, S] => [B, S, F]\n",
        "        x = x.movedim(1, 2)\n",
        "        # [B, S, F] => [B, S, H]\n",
        "        x, _ = self.rnn(x)\n",
        "        # [B, S, H] => [B, H]\n",
        "        # toma el último paso, participación 1\n",
        "        x = x[:, -1, :]\n",
        "        # [B, H] = [B, 11]\n",
        "        x = self.cls(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zQc5Gl_Oac4"
      },
      "outputs": [],
      "source": [
        "model = RNN().eval()\n",
        "model(torch.zeros(1, 10, 1024)).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZTgIN1jOac5"
      },
      "source": [
        "### 3.2 Inspección de arquitectura"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uq4AH_Z-Oac5"
      },
      "outputs": [],
      "source": [
        "summary(model, (1, 10, 1024), device='cpu', verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Tjz-hD9Oac5"
      },
      "source": [
        "## 4 Entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "725gOFVAOac5"
      },
      "source": [
        "### 4.1 Ciclo de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TheNZqp_Oac6"
      },
      "outputs": [],
      "source": [
        "# optimizador\n",
        "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# ciclo de entrenamiento\n",
        "EPOCHS = 10\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    # modelo en modo de entrenamiento\n",
        "    model.train()\n",
        "    \n",
        "    # entrenamiento de una época\n",
        "    for x, y_true in trn_dl:\n",
        "        # hacemos inferencia para obtener los logits\n",
        "        y_lgts = model(x)\n",
        "        # calculamos la pérdida\n",
        "        loss = F.cross_entropy(y_lgts, y_true)\n",
        "        # vaciamos los gradientes\n",
        "        opt.zero_grad()\n",
        "        # retropropagamos\n",
        "        loss.backward()\n",
        "        # actulizamos parámetros\n",
        "        opt.step()\n",
        "\n",
        "    # desactivamos temporalmente la gráfica de cómputo\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # modelo en modo de evaluación\n",
        "        model.eval()\n",
        "        \n",
        "        losses, accs = [], []\n",
        "        # validación de la época\n",
        "        for x, y_true in tst_dl:\n",
        "            # hacemos inferencia para obtener los logits\n",
        "            y_lgts = model(x)\n",
        "            # calculamos las probabilidades\n",
        "            y_prob = F.softmax(y_lgts, 1)\n",
        "            # obtenemos la clase predicha\n",
        "            y_pred = torch.argmax(y_prob, 1)\n",
        "            \n",
        "            # calculamos la pérdida\n",
        "            loss = F.cross_entropy(y_lgts, y_true)\n",
        "            # calculamos la exactitud\n",
        "            acc = (y_true == y_pred).type(torch.float32).mean()\n",
        "\n",
        "            # guardamos históricos\n",
        "            losses.append(loss.item() * 100)\n",
        "            accs.append(acc.item() * 100)\n",
        "\n",
        "        # imprimimos métricas\n",
        "        loss = np.mean(losses)\n",
        "        acc = np.mean(accs)\n",
        "        print(f'E{epoch:2} loss={loss:6.2f} acc={acc:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kl1SIk-xOac6"
      },
      "source": [
        "## Participación 1\n",
        "\n",
        "Cambia la arquitectura para tomar el promedio de la secuencia de la última salida de la capa RNN en vez de tomar el último paso. Revisa la documentación de [`torch.mean`](https://pytorch.org/docs/stable/generated/torch.mean.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctx0YTQVOac6"
      },
      "source": [
        "## Participación 2\n",
        "\n",
        "Remplaza la capa [GRU](https://pytorch.org/docs/stable/generated/torch.nn.GRU.html) por una [LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}